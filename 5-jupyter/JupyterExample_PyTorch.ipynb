{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook example - PyTorch\n",
    "\n",
    "**What is this?**\n",
    "For now here I'll show-case how the most important parts work in PyTorch -  creating a tensor, creating a model, training a model, setting up a dataset. At the bottom of this notebook you'll find a link to a complete Cifar10 PyTorch tutorial. I'll give you a quick overview of the different parts the Cifar10 tutorial from PyTorch is based on. \n",
    "\n",
    "**What this is not.**\n",
    "This doesn't aims at explaining theoretical concepts or the math behind what's going on here. This is supposed to give you the chance to get your hands dirty and to understand what \"learning\" specifically means in Machine Learning. For theoretical background check out the listet ressources in our onboarding-section on Notion. \n",
    "\n",
    "Author: Nicolas Remerscheid, Github: [@NiWaRe](https://www.github.com/NiWaRe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim \n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image # only to display our image at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll go through the main different operations involved in creating and training an AI model. We'll focus specifically on what is needed in the official [Cifar10 Classifier Tutorial of PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=mnist). <br><br>\n",
    "To start off: Unlike MNIST, Cifar10 is a dataset containing many small photographs of 10 different objects (airplane, bird, cat, etc.). Here we'll be focussing on creating a **Classifier** for these 10 different object types. Specifically, the tutorial showcases how to build a state-of-the-art Deep Learning Model - a Convolutional Neural Network - which takes as input a normal image and outputs what object can be seen in the image. For example, if you make a photo of your cat and input it into a model, it will likely recognize that indeed it is a cat. <br><br>\n",
    "As a quick explanation: Deep Learning is a subfield of Machine Learning, and Machine Learning is a subfield of AI. Machine Learning groups all the algorithms where we don't choose to model the given data in a specific way - we don't explicitly choose the data to be based on a gaussian distribution for example (as is often done in mathematical models in physics). Rather we try to design an algorithm that learns what distribution the observed data could be coming from. In general, we try to do as few explicit assumptions about the origins of the data as possible and try to let an algorithm learn everything on its own - that's why it is called Machine \"Learning\". Deep Learning is a subfield of Machine Learning in which we mainly consider \"Deep Neural Networks\". Neural Networks are specific algorithms that are inspired by the human brain (in a very much simplified way). They are made up of so-called \"neurons\" (a simple mathematical function) which are grouped in so-called \"layers\". \"Deep\" Learning is called \"deep\" because it considers Neural Networks with many layers, i.e. which can be considered to be \"deep\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2000])\n"
     ]
    }
   ],
   "source": [
    "### TENSORS ###\n",
    "# In PyTorch we work with \"tensors\" - tensors are simply numbers \n",
    "# they are called \"tensors\", because you'll see later that we often use high-dimensional arrays in ML\n",
    "\n",
    "x = torch.Tensor([1.2])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oneNeuron(\n",
       "  (layer1): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### THE FIRST MODEL ###\n",
    "# To create a Machine Learning Model we create a specific class \n",
    "# it has always this structure\n",
    "\n",
    "class oneNeuron(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(oneNeuron, self).__init__()\n",
    "        # important part nr. 1 #\n",
    "        # here we define what components our model should be composed of\n",
    "        \n",
    "        # a simple linear function: f(x) = w*x + b, w = weights, b = bias \n",
    "        # x is 3D\n",
    "        self.layer1 = nn.Linear(3, 1)\n",
    "        \n",
    "        # a  simple non-linear function, called ReLU. f(x) = max(x, 0)\n",
    "        # this is one of the most commonly used \"activation\" function\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # important part nr. 2 #\n",
    "        # here we define how we combine the components, which we defined above, \n",
    "        # and calculate the ouput for a given input x\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# here we create an instance of our model \n",
    "model = oneNeuron()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0473], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### THE FIRST AI PREDICTION ###\n",
    "# Now we do our first \"forward pass\" - we compute the ouput of our model for input x (e.g. an image)\n",
    "# later, in the tutorial, y will be the recognized class (what object can be seen on an image)\n",
    "x = torch.Tensor([2.3, 4.5, 2.1])\n",
    "y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight', tensor([[-0.2535,  0.1859, -0.0088]])),\n",
       "             ('layer1.bias', tensor([-0.1875]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### THE MODEL PARAMETERS ###\n",
    "# What do we want to learn? The parameters of our model: w and b \n",
    "# We call state_dict to display the \"state\" of our model, the existing parameters and their current value\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE FIRST TRAINING ###\n",
    "# To train we have to adjust our parameters based on the error we made (we rcognized a dog instead of a cat)\n",
    "\n",
    "# We define a loss - mean squared error is very standard\n",
    "loss = nn.MSELoss() \n",
    "\n",
    "# We define an optimizer - this is the component that mimizes the loss/does the LEARNING \n",
    "# SGD = Stochastic Gradient Descent, very popular choice \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# We calculate the error we made - here we assume we wanted: f([2.3, 4.5, 2.1]) = 1 [f(x) = y]\n",
    "target_y = torch.tensor([1.])\n",
    "error = loss(y, target_y)\n",
    "\n",
    "# We do a \"backward pass\" - we calculate the gradients, i.e. we calculate how we need to change our params\n",
    "error.backward() \n",
    "\n",
    "# We LEARN - i.e. we update our parameters based on the error we made (using the gradients)\n",
    "# learning means taking a \"step\" in the right direction\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight', tensor([[-0.2097,  0.2716,  0.0312]])),\n",
       "             ('layer1.bias', tensor([-0.1685]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DID WE LEARN? ###\n",
    "# We check again on the \"state\" of the model parameters and see if they changed\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our first single neuron in PyTorch, there is only fundamental component you need to understand to be able to do the real PyTorch tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE9D40F4ED0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our target, the object on the image (a number from 0-9 for 10 different objects): \n",
      " 6 = FROG\n"
     ]
    }
   ],
   "source": [
    "### DATA ###\n",
    "# PyTorch has a couple of datasets which you can simply download \n",
    "# normally you would load in your data here. \n",
    "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "# behaves like an array - here we get the first element - an image of a FROG\n",
    "input, target = cifar10_dataset[0]\n",
    "display(input)\n",
    "print(f\"Our target, the object on the image (a number from 0-9 for 10 different objects): \\n {target} = FROG\")\n",
    "\n",
    "# in the tutorial you'll find \"transforms\" - these are there to transform the data before using it \n",
    "# that could be cropping the images, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YESSS, CONGRATS, YOU JUST \"TRAINED\" YOUR FIRST AI !!!\n",
    "Now, continue to the [Cifar10 Classifier Tutorial of PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=mnist) or use our material list on to learn more about the theoretical basics (in the onboarding section). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
